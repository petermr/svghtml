<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5638951</article-id><article-id pub-id-type="publisher-id">13595</article-id><article-id pub-id-type="doi">10.1038/s41598-017-13595-7</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Infrared light field imaging system free of fixed-pattern noise</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Coelho</surname><given-names>Pablo A.</given-names></name><address><email>pcoelho@udec.cl</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Tapia</surname><given-names>Jorge E.</given-names></name><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>P&#x000e9;rez</surname><given-names>Francisco</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Torres</surname><given-names>Sergio N.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6201-5326</contrib-id><name><surname>Saavedra</surname><given-names>Carlos</given-names></name><address><email>carlos.saavedra@udec.cl</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2298 9663</institution-id><institution-id institution-id-type="GRID">grid.5380.e</institution-id><institution>Departamento de Ingenier&#x000ed;a El&#x000e9;ctrica, Universidad de Concepci&#x000f3;n, Casilla, </institution></institution-wrap>160-C Concepci&#x000f3;n, Chile </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2298 9663</institution-id><institution-id institution-id-type="GRID">grid.5380.e</institution-id><institution>Center for Optics and Photonics, Universidad de Concepci&#x000f3;n, Casilla, </institution></institution-wrap>4012 Concepci&#x000f3;n, Chile </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2298 9663</institution-id><institution-id institution-id-type="GRID">grid.5380.e</institution-id><institution>Departamento de F&#x000ed;sica, Universidad de Concepci&#x000f3;n, Casilla, </institution></institution-wrap>160-C Concepci&#x000f3;n, Chile </aff></contrib-group><pub-date pub-type="epub"><day>12</day><month>10</month><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>12</day><month>10</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>7</volume><elocation-id>13040</elocation-id><history><date date-type="received"><day>6</day><month>6</month><year>2017</year></date><date date-type="accepted"><day>26</day><month>9</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2017</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Digital photonic sensors have greatly evolved to maximize sensitivity and spatial, spectral, and temporal imaging resolution. For low-energy photons, new designs have generated new types of noise that degrade the formed-image signal-to-noise ratio to values lower than 1. Fixed-pattern noise (FPN), which is produced by the non-uniform focal-plane-array optoelectronics response, is an ill-posed problem in infrared and hyperspectral imaging science. Here, we experimentally show that the FPN behaves as an object at a depth of infinity when a light field is captured by an imaging system. The proposed method is based on the capture of the light field of a scene and digital refocusing to any nearby objects in the scene. Unlike standard techniques for FPN reduction, our method does not require knowledge of the physical parameters of the optoelectronic transducer, the motion scene, or the presence of off-line blackbody sources. The ability of the proposed method to reduce FPN is measured by evaluating the structural similarity (SSIM) index employing a blackbody-based FPN reduction technique as a reference. This new interpretation of the FPN opens avenues to create new cameras for low-energy photons with the ability to perform denoising by digital refocusing.</p></abstract><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2017</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">Researchers in the field of digital imaging technology are constantly attempting to improve image resolution, whether in spatial, spectral or temporal quality, particularly because such capabilities are required to discover new information in fields such as astronomy, medicine, and biology, among many others. Imaging technologies present distinct types of noise characteristics, varying in intensity, features, and nature. For example, the noise characteristics of various infrared (IR) imaging systems vary in intensity and spatial and temporal features depending on the nature of the IR-radiation transducer and the electronics of the readout integrated circuit (ROIC). These noise characteristics become superimposed on the captured IR radiation, thus causing image degradation, which can be observed by naked-eye visual inspection when viewing a raw digital image, since the resulting images exhibit a signal-to-noise ratio lower than 1. The numerous varieties of noise that affect imaging systems<sup><xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR4">4</xref></sup>, can be classified based on their temporal characteristics. Some noise sources vary as rapidly in time as the imaging system integration time. In contrast, other noise sources remain fixed for many integration time periods, forming a static pattern over the scene, as if one were viewing the image through a dirty or streaked window. This latter type of noise is typically called fixed-pattern noise (FPN) and is attributed to manufacturing imperfections, inhomogeneous pixel responsivities, dark currents of detectors, and typical readout architectures, such as a passive-pixel sensor or active-pixel sensor, introducing both temporal and spatially FPN<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. In general terms, non-uniformity correction techniques can be classified into two main families: calibration-based and scene-based techniques<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. The calibration method uses an absolute temperature reference; for this purpose, we used a blackbody radiation source, and for quantitative estimation of quality assessment, we used the blackbody radiation two-point (BBRTP) calibration method. Scientific applications require the highest radiometric precision available; thus, bulky and expensive calibration sources must be employed frame-by-frame to reduce FPN. In contrast, military applications and certain industrial applications require on-line classification capabilities; in this case, transducer technology, ROIC technology, and application dependency model-based algorithms must be specially designed and tuned to filter out the FPN on a case-by-case basis.</p><p id="Par3">Here, we present technology- and application-independent solutions to the problem of FPN in the context of wide-band IR imaging systems. However, the proposed solution can also be tested in visible-IR-hyperspectral and terahertz imaging systems. The key idea is to realize that FPN behaves as an optical object located at an image depth of infinity. When a collection of images in the same scene is captured with relative displacement between them, such as a scene image light field, such set can be used to achieve digital refocusing to any nearby objects in the scene. Naturally, this approach filters out the FPN as a consequence of the defocusing. This denoising is based on the most notable property of this type of noise, namely, that its location is fixed on the images over time.</p><p id="Par4">To explain this new concept, we show in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> a simplified scene where FPN is depicted as an optical object located at the depth infinity. The Z coordinate describes the scene depth. The baseline of the camera is at the position Z<sub>0</sub>, the plane of nearby objects is at the position Z<sub>1</sub>, intermediate objects are located at the position Z<sub>2</sub>, and the FPN at <italic>Z</italic>
<sub>&#x0221e;</sub> represents the optical infinity of the system.<fig id="Fig1"><label>Figure 1</label><caption><p>Schematic of the FPN as an object at a depth of infinity, <italic>Z</italic>
<sub>&#x0221e;</sub>. The imaging system superimposes the same noise pattern on the captured images of the scene when located at the spatial positions (Z<sub>0</sub>, <italic>X</italic>
<sub>0</sub>) and (Z<sub>0</sub>, <italic>X</italic>
<sub>1</sub>). Thus, regarding the relative position of the objects in the scene, the FPN appears as an object at a depth of infinity. This property of the FPN creates a parallax effect when observing close objects (e.g., objects at Z<sub>1</sub> and Z<sub>2</sub>) from the positions <italic>X</italic>
<sub>0</sub> and <italic>X</italic>
<sub>1</sub>.</p></caption><graphic xlink:href="41598_2017_13595_Fig1_HTML" id="d29e334"/></fig>
</p><p id="Par5">This new way of treating the FPN as an optical object at a depth of infinity allows one to develop a global solution to the problem of FPN reduction. Specifically, in this work, we build a plenoptic system with an IR camera with high FPN content using scanning. We show that it is possible to perform denoising by defocusing the FPN. For this purpose, the light field <italic>L</italic>
<sub><italic>f</italic></sub> of the scene (plenoptic collection of images that captures scene information as a 4-dimensional function) is processed using a digital refocused algorithm<sup><xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR11">11</xref></sup>. In this work, we decided to employ the seminal work developed by Ren Ng<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> known as the Fourier slice photography theorem. As a result of performing digital refocus, the effect of the FPN on objects at planes close to the imaging system is significantly mitigated. The level of noise reduction is quantified by the structural similarity (SSIM) index<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, showing that it is possible to obtain a high degree of FPN cancellation using as a reference a blackbody-based FPN calibration technique.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><p id="Par6">The reconstruction of digitally refocused images at far object planes shows severe FPN. However, we shall show that FPN is continuously reduced when refocused images at closer object planes are reconstructed by applying the refocusing algorithm to the captured light field.</p><p id="Par7">The image of Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref> shows the scene that was captured by the plenoptic IR system (using a Cedip camera and scanning to produce a matrix of 16&#x02009;&#x000d7;&#x02009;16 images with a step of 15&#x02009;mm), which corresponds to an industrial sector with slow temperature variations with high thermal contrast contents. The Cedip camera is a JADE-UC uncooled microbolometer focal-plane-array (FPA) model that operates in the long-wave IR range of 8 to 12 &#x003bc;m and is equipped with a 14-bits, 320&#x02009;&#x000d7;&#x02009;240&#x02009;FPA.<fig id="Fig2"><label>Figure 2</label><caption><p>FPN reduction attained by the proposed method for the Cedip IR camera in an industrial scene. (<bold>a</bold>) Raw image and region of interest (RoI) with a high presence of FPN, which lies inside the segmented-lines rectangle and it corresponds to an industrial gas cylinder. (<bold>b</bold>) The scene image and RoI for the nearest scene objects corrected by the BBRTP method. (<bold>c</bold>&#x02013;<bold>g</bold>) RoI reconstructed using the proposed method at the focal planes: (<bold>c</bold>) <italic>N</italic>&#x02009;=&#x02009;1, (<bold>d</bold>) <italic>N</italic>&#x02009;=&#x02009;70, (<bold>e</bold>) <italic>N</italic>&#x02009;=&#x02009;140, (<bold>f</bold>) <italic>N</italic>&#x02009;=&#x02009;174, and (<bold>g</bold>) <italic>N</italic>&#x02009;=&#x02009;240 for the closest object.</p></caption><graphic xlink:href="41598_2017_13595_Fig2_HTML" id="d29e422"/></fig>
</p><p id="Par8">The image of Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref> was FPN corrected by using the two-point calibration method (TPC)<sup><xref ref-type="bibr" rid="CR13">13</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref></sup>, that utilizes a first-order model for the camera response. This calibration technique was applied using two uniform radiation sources acquired from two high-accuracy blackbody radiators in the Mikron M300 series, at 20&#x02009;&#x000b0;C and 30&#x02009;&#x000b0;C, respectively.</p><p id="Par9">The region of interest (RoI) in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref> is shown as a rectangle of segmented lines. This RoI corresponds to a gas cylinder located 3 m from the camera (closest object in the image scene) and is used to enable a comparison of results for this entire work. It is important to note that we have used the most complex camera pixel region to locate our object of study since there are two bright spot artifacts in the image (attributed to partially saturated pixels of the FPA).</p><p id="Par10">Figure&#x000a0;<xref rid="Fig2" ref-type="fig">2b</xref> shows the same image of Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref> without FPN correction; this is a raw image, and corresponds to an image of the <italic>L</italic>
<sub><italic>f</italic></sub> with severe FPN. From left to right, Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2c</xref> shows a sequence of 5 RoI images corresponding to the refocusing planes, namely, c) <italic>N</italic>&#x02009;=&#x02009;1, d) <italic>N</italic>&#x02009;=&#x02009;70, e) <italic>N</italic>&#x02009;=&#x02009;140, f) <italic>N</italic>&#x02009;=&#x02009;174 (the exact refocused image), and g) <italic>N</italic>&#x02009;=&#x02009;240, thereby suppressing FPN. The reduction of noise by defocusing is limited by the nearest refocused object plane. In other words, we must determine the <italic>N</italic> associated with the plane of the focused near object. For this case, the value is <italic>N</italic>&#x02009;=&#x02009;174, and it is obtained using the level of focus algorithm based on the Brenner function<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup>, which coincides with naked-eye visual observations.</p><p id="Par11">The degree of denoising FPN was quantified by SSIM index<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, which employs an image reference free of FPN and the corresponding image at a refocused image from the raw-data light field. The range of this index are values from 0 to 1, where the lowest value (SSIM&#x02009;=&#x02009;0) corresponds to entirely different images and the highest value (SSIM&#x02009;=&#x02009;1) corresponds to identical images. Thus, we used the BBRTP calibration method, which allows generating the reference sets of light fields when applying the method to the raw-data light field. When applying the plenoptic algorithm for quantitative comparison, the refocused images generated from the raw-data light field are always compared with the refocused images from the BBRTP light field; thus, the SSIM index is a distance measure between these refocused images.</p><p id="Par12">We studied the level of FPN reduction on the RoI by digital refocusing at 300 different object planes. As a reference, we used the same RoI images corrected using the BBRTP method. Since the images being compared differ only in the amount of FPN, a high value of the SSIM index is directly associated with a high level of noise reduction. We emphasize based on our experience that values greater than 0.4 correspond to levels of noise reduction that make the residual FPN imperceptible in naked-eye inspection. Additionally, an SSIM index greater than 0.4 means that the FPN has been reduced to an extent to which objects can be distinguished in the image. Note that in IR imaging artefacts such as dead, saturated, and flickering pixels and any computational imaging processing may change the IR contrast of the raw scene imaging. Thus, the SSIM index primarily corresponds to the SSIM of the objects within the IR image.</p><p id="Par13">The graph in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> shows the dependence of the SSIM index versus the refocusing parameter, <italic>N</italic>, of the nearby object presented in the RoI. The first values of <italic>N</italic> correspond to distant planes, where there is a high presence of FPN, as evidenced by reaching SSIM values lower than 0.13. As the closest planes are refocused (corresponding to large values of N), the FPN begins to defocus. This result is most strongly pronounced in the first 100 refocused planes, where the SSIM index increases from 0.13 to 0.49. Although there is a tendency to continue improving the FPN reduction, we can use the focused image only up to the value of <italic>N</italic>&#x02009;=&#x02009;174.<fig id="Fig3"><label>Figure 3</label><caption><p>Dependence of the spatial SSIM index versus the dimensionless parameter <italic>N</italic>, which represents the different focal planes.</p></caption><graphic xlink:href="41598_2017_13595_Fig3_HTML" id="d29e522"/></fig>
</p><p id="Par14">To experimentally demonstrate that the method works satisfactorily in different scenarios, we apply the proposed method to two additional scenes. The first scene, shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, corresponds to a winter scene where only half of the scene is under direct sunlight illumination. The second scene, shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, corresponds to a daylight city-landscape in the spring. In Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, we selected two regions of interest, a portion of the roof of a warehouse and a street light, which are shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4c,e</xref> at refocused object planes with <italic>N</italic>&#x02009;=&#x02009;47 and <italic>N</italic>&#x02009;=&#x02009;100, respectively. In both cases, the structures can be recognized within the RoI, which does not occur in the raw-data in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4a</xref>. Similarly, in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> we selected two regions of interest, a portion of the tree and a shrubbery, which are shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5c,e</xref> at refocused object planes with <italic>N</italic>&#x02009;=&#x02009;70 and <italic>N</italic>&#x02009;=&#x02009;117, respectively. Again, in both cases, the structures can be recognized in the RoI, which does not occur in the raw-data in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5a</xref>. The entire datasets for the above described light fields are publicly available, both raw data and BBRTP calibrated data<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>.<fig id="Fig4"><label>Figure 4</label><caption><p>Winter season scene in which only half of the scene is under direct sunlight illumination. (<bold>a</bold>) Raw image from the light field, where two RoI are highlighted with rectangles. (<bold>b</bold>) Image from the light field obtained by applying the BBRTP calibration method to the raw-data. (<bold>c</bold> and <bold>e</bold>) Shows refocused object planes with <italic>N</italic>&#x02009;=&#x02009;47 (roof of a near house, SSIM &#x02009;=&#x02009;0.55) and <italic>N</italic>&#x02009;=&#x02009;100 (public luminary, SSIM &#x02009;=&#x02009;0.54), respectively. (<bold>d</bold> and <bold>f</bold>) Are the same as (<bold>c</bold> and <bold>e</bold>), respectively, for the BBRTP-calibrated images.</p></caption><graphic xlink:href="41598_2017_13595_Fig4_HTML" id="d29e607"/></fig>
<fig id="Fig5"><label>Figure 5</label><caption><p>Daylight city-landscape scene in the spring. (<bold>a</bold>) Raw image from the light field, where the RoI are highlighted with rectangles. (<bold>b</bold>) Image from the light field obtained by applying the BBRTP calibration method to the raw-data. (<bold>c</bold>) and (<bold>e</bold>) show refocused object planes with <italic>N</italic>&#x02009;=&#x02009;70 (tree, SSIM &#x02009;=&#x02009;0.65) and <italic>N</italic>&#x02009;=&#x02009;117 (shrubbery, SSIM &#x02009;=&#x02009;0.77), respectively. (<bold>d</bold>) and (<bold>f</bold>) are the same as (<bold>c</bold>) and (<bold>e</bold>), respectively, for the BBRTP-calibrated images.</p></caption><graphic xlink:href="41598_2017_13595_Fig5_HTML" id="d29e648"/></fig>
</p><p id="Par15">The results show that the proposed noise cancellation method reaches significant levels of FPN reduction. Such FPN reductions are quantified by SSIM index reaching values corresponding to a human naked eye&#x02019;s structure recognition. Of course, the SSIM index difference with respect to the blackbody FPN method is not attributable to the structural objects scene recovering process, but to the contrast modification introduced by both techniques to the raw-data in the process of the FPN correction. Notably, unlike standard techniques<sup><xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR23">23</xref></sup>, our method does not require knowing physical parameters associated with the optoelectronic transducer system with which the images are acquired, the motion scene, or the presence of off-line blackbodies for estimation of non-uniformity sensor parameters.</p><p id="Par16">Evaluating the effectiveness of the proposed method for reducing the FPN on different IR transducer technologies, where each type of transducer presents FPN with distinctive features, is quite interesting. Using pre-recorded blackbody data and the previously used <italic>L</italic>
<sub><italic>f</italic></sub> corrected by BBRTP, it is possible to artificially generate an <italic>L</italic>
<sub><italic>f</italic></sub> containing real FPN from the blackbody data. For this experiment, three additional cameras from different technologies are considered. The first camera is a commercial Amber camera, model AE-4128, which operates in the mid-wave infrared (MWIR) (3&#x02013;5&#x02009;&#x003bc;m) region and is equipped with a cooled InSb FPA with 128&#x02009;&#x000d7;&#x02009;128 pixels and 16-bits resolution. The second one is a commercial Lumasense MWIR camera, model MC320MHT, which operates in the range of 3&#x02013;5&#x02009;&#x003bc;m and uses a 16-bit uncooled FPA of 320&#x02009;&#x000d7;&#x02009;240 pixels. The third camera is a quantum-dots infrared photodetector (QDIP) camera, which operates in the mid- and long-wave IR regions (3&#x02013;5&#x02009;&#x003bc;m and 8&#x02013;12&#x02009;&#x003bc;m), is equipped with an InAs QDs/InGaAs/GaAs cooled FPA of 356&#x02009;&#x000d7;&#x02009;240 pixels, and quantizes data in 14-bits. For this experiment, blackbody samples of each camera at two different temperatures were used. These samples were taken without the use of built-in FPN compensation options. Specifically, blackbody samples were recorded by the Amber camera at temperatures of 20&#x02009;&#x000b0;C and 30&#x02009;&#x000b0;C, by the Lumasense camera at 100&#x02009;&#x000b0;C and 350&#x02009;&#x000b0;C, and by the QDIP camera at 26&#x02009;&#x000b0;C and 50&#x02009;&#x000b0;C. By employing these data and a TPC version of the <italic>L</italic>
<sub><italic>f</italic></sub>, the noise pattern of these technologies is artificially superimposed on the clean <italic>L</italic>
<sub><italic>f</italic></sub> using a first-order approximation for the response of the camera<sup><xref ref-type="bibr" rid="CR13">13</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref></sup>, Subsequently, the <italic>L</italic>
<sub><italic>f</italic></sub> with FPN is generated, and the proposed method is applied (see Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>).<fig id="Fig6"><label>Figure 6</label><caption><p>Method evaluation for different scenarios. Set of 19 object planes for various IR transducer technologies, from top to bottom: (<bold>a</bold>) Amber, (<bold>b</bold>) Lumasense, (<bold>c</bold>) QDIP, and (<bold>d</bold>) Cedip IR cameras. (<bold>e</bold>) SSIM index versus refocusing planes: Amber, dashed-line (grey); Lumanesense, dashed-dotted line (green); QDIP, dotted line (red); and Cedip, solid line (blue). (<bold>f</bold>) SSIM index for QDIP IR technology for two different <italic>L</italic>
<sub><italic>f</italic></sub> architectures, namely, an <italic>L</italic>
<sub><italic>f</italic></sub> formed with a single camera scanning (dotted line) and a <italic>L</italic>
<sub><italic>f</italic></sub> formed with a set of <italic>m</italic>&#x02009;&#x000d7;&#x02009;<italic>n</italic> cameras (solid line).</p></caption><graphic xlink:href="41598_2017_13595_Fig6_HTML" id="d29e764"/></fig>
</p><p id="Par17">From top to bottom, Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6a</xref> shows the outcome of refocusing the RoI for the Amber, Lumasense, QDIP and Cedip Technologies. The first image of each row corresponds to an image of the <italic>L</italic>
<sub><italic>f</italic></sub> with the noise of each transducer technology, and the images to the right show the RoI at different refocusing planes that are separated from each other by a &#x00394;<italic>N</italic>&#x02009;=&#x02009;10. The last image corresponds to the best-refocused plane, which is for <italic>N</italic>&#x02009;=&#x02009;174. In all of the cases, we considered the use of a single camera when generating the corresponding <italic>L</italic>
<sub><italic>f</italic></sub>; namely, for each IR technology, a unique noise pattern was rendered on all the <italic>L</italic>
<sub><italic>f</italic></sub> images. Note that the Cedip thermal transducer generates the strongest FPN. Indeed, for this case, the scene object cannot be distinguished from the noise. Figure&#x000a0;<xref rid="Fig6" ref-type="fig">6b</xref> shows the SSIM index versus digital refocused planes for the four analyzed technologies. In all the cases, the object in the RoI is focused at the plane <italic>N</italic>&#x02009;=&#x02009;174, and for all the photonic transducers, the SSIM is higher than 0.8 at that object plane. For the Cedip thermal transducer technology, the <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SSIM=0.49$$\end{document}</tex-math><mml:math id="M2"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.49</mml:mn></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq1.gif"/></alternatives></inline-formula> at <italic>N</italic>&#x02009;=&#x02009;174. Note that an SSIM index value greater 0.4 means that objects can be distinguished in the image. Among all the technologies, the largest reduction of FPN is achieved for the photonic transducer QDIP camera, which begins with an index of structural similarity <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SSIM=0.04$$\end{document}</tex-math><mml:math id="M4"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.04</mml:mn></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq2.gif"/></alternatives></inline-formula> and later reaches a value of <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SSIM=0.90$$\end{document}</tex-math><mml:math id="M6"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.90</mml:mn></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq3.gif"/></alternatives></inline-formula> (close planes). The greatest FPN reduction is achieved for the photonic transducer Amber technology with a <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SSIM=0.98$$\end{document}</tex-math><mml:math id="M8"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.98</mml:mn></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq4.gif"/></alternatives></inline-formula>.</p><p id="Par18">Furthermore, to show the robustness of the proposed method, we conducted three complementary performance evaluations. The first one considers another way to record an IR <italic>L</italic>
<sub><italic>f</italic></sub>. In Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6c</xref>, we plot the variation of the spatial SSIM index for two different architectures when generating the <italic>L</italic>
<sub><italic>f</italic></sub> for the QDIP technology (with photonic transducers). The first architecture is a single camera and a scanning system, and therefore, a single noise pattern is replicated in all the images of the <italic>L</italic>
<sub><italic>f</italic></sub> (dotted line). In contrast, the second architecture considers a different camera of the same technology for each image of the <italic>L</italic>
<sub><italic>f</italic></sub> (solid line). This design is simulated by using the procedure<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> for synthesizing different FPN samples that preserve the technology-dependent spatial structure of the real FPN of a camera. As shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6c</xref>, the method performs equally well under both types of FPA architectures for generating the corresponding <italic>L</italic>
<sub><italic>f</italic></sub>. This result provides clear evidence of the robustness of the proposed method under different <italic>L</italic>
<sub><italic>f</italic></sub> architectures.</p><p id="Par19">The second and third complementary performance evaluations were conducted using the Cedip camera and scanning. To study how reducing the <italic>L</italic>
<sub><italic>f</italic></sub> size affects FPN cancellation, three cases are presented in the second evaluation. Specifically, a light field of 16&#x02009;&#x000d7;&#x02009;16 images was reduced to 8&#x02009;&#x000d7;&#x02009;8 and 4&#x02009;&#x000d7;&#x02009;4 images while maintaining a step between adjacent images of 15&#x02009;mm.</p><p id="Par20">Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> indicates that a reduction of the <italic>L</italic>
<sub><italic>f</italic></sub> size produces a reduction of the SSIM index from <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SSIM=0.49$$\end{document}</tex-math><mml:math id="M10"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.49</mml:mn></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq5.gif"/></alternatives></inline-formula> to <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SSIM=0.47$$\end{document}</tex-math><mml:math id="M12"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.47</mml:mn></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq6.gif"/></alternatives></inline-formula>. Regarding FPN reduction performance, we see that a smaller <italic>L</italic>
<sub><italic>f</italic></sub> shows little diversity of spatial frequencies and generates refocused images with greater depth, which makes smaller <italic>L</italic>
<sub><italic>f</italic></sub> relatively limited in regards to forming a discrete plane of refocused elements. This constraint does not allow a precise selection of information; therefore, the residual noise of the FPN structure remains even when one focuses only on the object of interest located in a near optical plane. However, in all cases, the SSIM index is similar to the ones computed for an <italic>L</italic>
<sub><italic>f</italic></sub> of 16&#x02009;&#x000d7;&#x02009;16 images. Note that this phenomenon occurs even in the event of the smallest <italic>L</italic>
<sub><italic>f</italic></sub> that contains only 4&#x02009;&#x000d7;&#x02009;4 images.<table-wrap id="Tab1"><label>Table 1</label><caption><p>SSIM index for <italic>L</italic>
<sub><italic>f</italic></sub> formed with a different number of images.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>
<italic>m</italic>&#x02009;&#x000d7;&#x02009;<italic>n</italic>
</th><th>&#x00394;<italic>x</italic> [mm]</th><th>
<italic>N</italic>
</th><th>SSIM</th></tr></thead><tbody><tr><td>4&#x02009;&#x000d7;&#x02009;4</td><td>15</td><td>43</td><td>0.47</td></tr><tr><td>8&#x02009;&#x000d7;&#x02009;8</td><td>15</td><td>94</td><td>0.47</td></tr><tr><td>16&#x02009;&#x000d7;&#x02009;16</td><td>15</td><td>174</td><td>0.49</td></tr></tbody></table></table-wrap>
</p><p id="Par21">In the third case, the performance of the method is studied on 16&#x02009;&#x000d7;&#x02009;16-image light fields with a different step size between adjacent images. Three different <italic>L</italic>
<sub><italic>f</italic></sub> with steps of 15&#x02009;mm, 10&#x02009;mm and 5&#x02009;mm were experimentally acquired. The results of applying the proposed method to each one of these light fields are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>SSIM index for different spatial separation between <italic>L</italic>
<sub><italic>f</italic></sub> consecutive images.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>
<italic>m</italic>&#x02009;&#x000d7;&#x02009;<italic>n</italic>
</th><th>&#x00394;<italic>x</italic> [mm]</th><th>
<italic>N</italic>
</th><th>SSIM</th></tr></thead><tbody><tr><td>16&#x02009;&#x000d7;&#x02009;16</td><td>5</td><td>63</td><td>0.51</td></tr><tr><td>16&#x02009;&#x000d7;&#x02009;16</td><td>10</td><td>118</td><td>0.48</td></tr><tr><td>16&#x02009;&#x000d7;&#x02009;16</td><td>15</td><td>174</td><td>0.49</td></tr></tbody></table></table-wrap>
</p><p id="Par22">As shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, by reducing the separation between images, the number of planes between optical infinity and the best-refocused plane for the closest object decreases in number, from 174 planes to only 63. This decrease coarsens the depth of field at each discrete plane, which limits the refocusing precision on specific objects, although the SSIM index is not affected significantly, and the quality of the images is maintained.</p></sec><sec id="Sec3" sec-type="discussion"><title>Discussion</title><p id="Par23">We have proposed a new technology-transducer and application-independent method for FPN reduction that does not rely on the use of physical information of the FPA or on using external reference scenes (such as calibrated blackbody sources). In particular, we have experimentally demonstrated the effectiveness of the proposed method in the case of a scanning plenoptic IR system with a single camera. The method was tested by varying the size of the captured <italic>L</italic>
<sub><italic>f</italic></sub> and varying the displacement between consecutive images in the <italic>L</italic>
<sub><italic>f</italic></sub>. These tests allow one to appreciate that noise reduction is robust under both variations of the experimental configuration. Notably, a small <italic>L</italic>
<sub><italic>f</italic></sub> of 4&#x02009;&#x000d7;&#x02009;4 images produces a high increase of the SSIM index, which makes this method very promising for future IR imaging and a visible-IR-hyperspectral imaging system with <italic>L</italic>
<sub><italic>f</italic></sub> ability.</p><p id="Par24">Furthermore, we have demonstrated the robustness of the method for three other IR transducer technologies, using digital addition of real FPN characteristics from each technology in our <italic>L</italic>
<sub><italic>f</italic></sub> free of FPN. In all cases, we obtained high noise cancellation, which strongly suggests that the method is technology independent. For studied technologies, the most notable FPN reduction occurs for the QDIP camera, for which the SSIM concerning the FPN free reference increases by 0.86. We also performed simulations of plenoptic <italic>L</italic>
<sub><italic>f</italic></sub> obtained with an array of IR cameras, where each one of the <italic>L</italic>
<sub><italic>f</italic></sub> images was captured by an independent camera. Here, each image has different FPN structures, and the remarkable property of the method is that even in such cases, the noise reduction is efficient and comparable to the case of using a single camera and scanning system for capturing the <italic>L</italic>
<sub><italic>f</italic></sub> (same FPN for all the images).</p><p id="Par25">In the next few years, the proposed method is expected to have technological implications in the development of new cameras, for low-energy photons, such as IR and terahertz cameras, and for visible and IR spectral selected photons (hyperspectral cameras) with the ability to perform denoising by digital refocusing.</p></sec><sec id="Sec4" sec-type="materials|methods"><title>Methods</title><p id="Par26">One method to acquire a scene <italic>L</italic>
<sub><italic>f</italic></sub> is through a two-dimensional transverse scanning employing a single camera, see Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7a</xref>. This <italic>L</italic>
<sub><italic>f</italic></sub> capture procedure was implemented with the following equipment: an optical bench, a high-precision linear translation stage with a displacement range of 600&#x02009;mm with DC motor and rotary encoder (model: IMS600CC, Newport), a high-precision vertical translation stage (minimal translation of 1.25 &#x003bc;m) with a displacement range of 300&#x02009;mm and with a DC motor (IMS-V Series, model: IMS300V, Newport) mounted on a right angle bracket (model: EQ120, Newport), and a 2-axis universal driver with an Ethernet connection (model: XPS-Q2, Newport) for controlling of vertical and horizontal translation stages. The digital camera was a Jade-UC, Cedip Inc., which integrates the incident radiance using an uncooled microbolometer FPA sensor of 320&#x02009;&#x000d7;&#x02009;240 pixels that operates in the range of 8&#x02013;12&#x02009;&#x003bc;m and has a dynamic range of 14-bits. This camera was operated without using its built-in FPN compensation options (raw-data imaging), and the formation of the image on the sensor used a focal length lens of <italic>f</italic>&#x02009;=&#x02009;24&#x02009;mm and an <italic>F</italic>-number of <italic>F</italic>&#x02009;=&#x02009;1.1.<fig id="Fig7"><label>Figure 7</label><caption><p>(<bold>a</bold>) Experimental configuration for the acquisition of the individual images at the light field using transversal scanning, where the IR Cedip camera has been installed in a high precision positioning system. (<bold>b</bold>) Experimental configuration for capturing raw images from a uniform scene from a blackbody-radiation-calibrated source Mikron 345. Two images are registered with the blackbody radiation source at 20&#x02009;&#x000b0;C and 30&#x02009;&#x000b0;C. (<bold>c</bold>) Light field with the presence of FPN on an 8&#x02009;&#x000d7;&#x02009;8-images subset of the entire <italic>L</italic>
<sub><italic>f</italic></sub> of 16&#x02009;&#x000d7;&#x02009;16-images.</p></caption><graphic xlink:href="41598_2017_13595_Fig7_HTML" id="d29e1348"/></fig>
</p><p id="Par27">Through the overall equipment arrangement and operation, as shown in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>, the light field <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{f}(x,y;m,n)$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>;</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq7.gif"/></alternatives></inline-formula> was generated. The coordinates (<italic>x</italic>, <italic>y</italic>) correspond to the image pixels, and the coordinates (<italic>m</italic>, <italic>n</italic>) correspond to the position of each <italic>L</italic>
<sub><italic>f</italic></sub> image. In our case, the images were of 320&#x02009;&#x000d7;&#x02009;240 pixels in an arrangement of 16&#x02009;&#x000d7;&#x02009;16 images. The offset between (<italic>m</italic>, <italic>n</italic>) coordinates of the <italic>L</italic>
<sub><italic>f</italic></sub> was 15&#x02009;mm for the vertical and horizontal directions.</p><p id="Par28">The digital refocusing was accomplished by means of the Fourier slice photography theorem<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mathscr{P}}}_{\alpha }[{L}_{f}]={ {\mathcal F} }^{-2}\circ {{\mathfrak{B}}}_{\alpha }\circ { {\mathcal F} }^{4}[{L}_{f}],$$\end{document}</tex-math><mml:math id="M16" display="block"><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>&#x02131;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02218;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="fraktur">B</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02218;</mml:mo><mml:msup><mml:mrow><mml:mi>&#x02131;</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:msup><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41598_2017_13595_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par29">Using the digital refocusing operator, <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mathscr{P}}}_{\alpha }$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq8.gif"/></alternatives></inline-formula>, it is possible to select a scene&#x02019;s spatial frequency information from <italic>L</italic>
<sub><italic>f</italic></sub> to reconstruct images focused on different object planes determined by the &#x003b1; parameter, where small &#x003b1; values correspond to far object planes. Thus, an effective refocused image on a fixed object plane is obtained through the two-dimensional inverse Fourier transform, <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ {\mathcal F} }^{(-\mathrm{2)}}$$\end{document}</tex-math><mml:math id="M20"><mml:msup><mml:mrow><mml:mi>&#x02131;</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>2)</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq9.gif"/></alternatives></inline-formula>, from a two-dimensional slice information, <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mathfrak{B}}}_{\alpha }$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mrow><mml:mi mathvariant="fraktur">B</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq10.gif"/></alternatives></inline-formula>, from the Fourier transform in four-dimensions, <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ {\mathcal F} }^{\mathrm{(4)}}$$\end{document}</tex-math><mml:math id="M24"><mml:msup><mml:mrow><mml:mi>&#x02131;</mml:mi></mml:mrow><mml:mrow><mml:mn>(4)</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq11.gif"/></alternatives></inline-formula>. For this particular work, the &#x003b1; values are related to different focal planes obtained in such a way that every <inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N=\mathrm{1,\; 2,\; 3,}\cdots $$\end{document}</tex-math><mml:math id="M26"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1, 2, 3,</mml:mn><mml:mo>&#x022ef;</mml:mo></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq12.gif"/></alternatives></inline-formula> is associated with <inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\alpha }_{1}=\mathrm{0.999,}{\alpha }_{2}=\mathrm{0.998,}{\alpha }_{3}=0.997\ldots ,{\alpha }_{N}=1-0.001\times N$$\end{document}</tex-math><mml:math id="M28"><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999,</mml:mn><mml:msub><mml:mrow><mml:mspace width="0.25em"/><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.998,</mml:mn><mml:msub><mml:mrow><mml:mspace width="0.25em"/><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.997</mml:mn><mml:mi>&#x02026;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="41598_2017_13595_Article_IEq13.gif"/></alternatives></inline-formula>, which take values equally spaced between them. Finally, 300 effective refocused images were reconstructed and arranged from the scene image farthest object plane to the closest object plane, i.e., from <italic>N</italic>&#x02009;=&#x02009;1 to <italic>N</italic>&#x02009;=&#x02009;300.</p><p id="Par30">To quantify the quality assessment of the proposed method for denoising FPN, we used the SSIM index<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, which allows one to quantify the SSIM between a reference image and a distorted image by considering their luminance, contrast, and structure by considering that these three parameters are relatively independent. This index has been developed for the visible region of the electromagnetic spectrum by considering that human perception is adapted to extract structural information of scenes. In our case, as reference images in a particular refocused plane, we used those refocused images obtained from the BBRTP corrected light field, and the distorted images are refocused images from the raw-data light field.</p></sec></body><back><fn-group><fn><p>
<bold>Publisher's note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The authors acknowledge the financial support both from CONICYT grants, Basal Financing Program PFB0824 and FONDECYT 1160613. P.A. Coelho and J.E. Tapia acknowledge CONICYT Ph.D. scholarship.</p></ack><notes notes-type="author-contribution"><title>Author Contributions</title><p>P.C., J.T., and F.P. have executed the experiment and processed the data. S.T. and C.S. designed and assisted in the experiment. All authors agree to the contents of the paper.</p></notes><notes notes-type="COI-statement"><sec id="FPar1"><title>Competing Interests</title><p id="Par31">The authors declare that they have no competing interests.</p></sec></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scribner</surname><given-names>DA</given-names></name><name><surname>Kruer</surname><given-names>MR</given-names></name><name><surname>Killiany</surname><given-names>JM</given-names></name></person-group><article-title>Infrared focal plane array technology</article-title><source>Proceedings of the IEEE</source><year>1991</year></element-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Holst, G. C. <italic>CCD Arrays</italic>, <italic>Cameras and Displays</italic> (Society of Photo Optical, 1998), second edn.</mixed-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogalski</surname><given-names>A</given-names></name></person-group><article-title>Infrared detectors: An overview</article-title><source>Infrared Physics and Technology</source><year>2002</year><volume>43</volume><fpage>187</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/S1350-4495(02)00140-8</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>Y</given-names></name><name><surname>Tisse</surname><given-names>C-L</given-names></name></person-group><article-title>Single-image-based solution for optics temperature-dependent nonuniformity correction in an uncooled long-wave infrared camera</article-title><source>Optics letters</source><year>2014</year><volume>39</volume><fpage>646</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1364/OL.39.000646</pub-id><?supplied-pmid 24487887?><pub-id pub-id-type="pmid">24487887</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodall</surname><given-names>T</given-names></name><name><surname>Bovik</surname><given-names>AC</given-names></name><name><surname>Vikalo</surname><given-names>H</given-names></name><name><surname>Paulter</surname><given-names>NG</given-names></name></person-group><article-title>Non-uniformity Correction of IR Images using Natural Scene Statistics</article-title><source>IEEE Global Conference on Signal and Information Processing (GlobalSIP)</source><year>2015</year></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>R</given-names></name></person-group><article-title>Fourier slice photography</article-title><source>ACM Transactions on Graphics</source><year>2005</year><volume>24</volume><fpage>735</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1145/1073204.1073256</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Luan, Y., He, X., Xu, B., Yang, P. &#x00026; Tang, G. Automatic calibration method for plenoptic camera. <italic>Optical Engineering</italic><bold>55</bold>, 10.1117/1.OE.55.4.043111 (2016).</mixed-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>P</given-names></name><name><surname>Zhang</surname><given-names>R</given-names></name></person-group><article-title>A new freeform depth of field controlling method based on focused plenoptic camera</article-title><source>Journal of Computational Methods in Science and Engineering</source><year>2016</year><volume>16</volume><fpage>187</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.3233/JCM-160609</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinze</surname><given-names>C</given-names></name><name><surname>Spyropoulos</surname><given-names>S</given-names></name><name><surname>Hussmann</surname><given-names>S</given-names></name><name><surname>Perwass</surname><given-names>C</given-names></name></person-group><article-title>Automated Robust Metric Calibration Algorithm for Multifocus Plenoptic Cameras</article-title><source>IEEE Transactions on Instrumentation and Measurement</source><year>2016</year><volume>65</volume><fpage>1197</fpage><lpage>1205</lpage><pub-id pub-id-type="doi">10.1109/TIM.2015.2507412</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgiev</surname><given-names>T</given-names></name><name><surname>Lumsdaine</surname><given-names>A</given-names></name></person-group><article-title>Focused plenoptic camera and rendering</article-title><source>Journal of Electronic Imaging</source><year>2010</year><volume>19</volume><fpage>021106</fpage><pub-id pub-id-type="doi">10.1117/1.3442712</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Georgiev, T. &#x00026; Lumsdaine, A. Reducing plenoptic camera artifacts. <italic>Computer Graphics Forum</italic>, https://doi.org/10.1111/j.1467- 8659.2010.01662.x (2010).</mixed-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Bovik</surname><given-names>AC</given-names></name><name><surname>Sheikh</surname><given-names>HR</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><article-title>Image quality assessment: From error visibility to structural similarity</article-title><source>IEEE Transactions on Image Processing</source><year>2004</year><volume>13</volume><fpage>600</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1109/TIP.2003.819861</pub-id><?supplied-pmid 15376593?><pub-id pub-id-type="pmid">15376593</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perry</surname><given-names>D</given-names></name></person-group><article-title>&#x00026; Dereniak. Linear theory of nonuniformity correction in infrared staring sensors</article-title><source>Optical Engineering</source><year>1993</year><volume>32</volume><fpage>185</fpage><lpage>1859</lpage><pub-id pub-id-type="doi">10.1117/12.145601</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Schulz, M. &#x00026; Caldwell, L. Nonuniformity correction and correctability of infrared focal plane arrays. <italic>Infrared Physics &#x00026; Technology.</italic>10.1016/1350-4495(94)00002-3 (1995).</mixed-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez</surname><given-names>F</given-names></name><name><surname>Pezoa</surname><given-names>J</given-names></name><name><surname>Figueroa</surname><given-names>M</given-names></name><name><surname>Torres</surname><given-names>SN</given-names></name></person-group><article-title>Empirical frequency domain model for fixed-pattern noise in infrared focal plane arrays</article-title><source>Infrared Physics &#x00026; Technology</source><year>2014</year><volume>67</volume><fpage>413</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1016/j.infrared.2014.09.010</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>JF</given-names></name><etal/></person-group><article-title>An automated microscope for cytologic research a preliminary evaluation</article-title><source>The Journal of Histochemistry and Cytochemistry</source><year>1976</year><volume>24</volume><fpage>100</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1177/24.1.1254907</pub-id><?supplied-pmid 1254907?><pub-id pub-id-type="pmid">1254907</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santos</surname><given-names>A</given-names></name><etal/></person-group><article-title>Evaluation of autofocus functions in molecular cytogenetic analysis</article-title><source>J Microsc</source><year>1997</year><volume>188</volume><fpage>264</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1046/j.1365-2818.1997.2630819.x</pub-id><pub-id pub-id-type="pmid">9450330</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Coelho, P., Tapia, J. E., P&#x000e9;rez, F., Torres, S. N. &#x00026; Saavedra, C. Infrared light field datasets <ext-link ext-link-type="uri" xlink:href="http://osf.io/f8tr7">http://osf.io/f8tr7</ext-link> (2017).</mixed-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torres</surname><given-names>SN</given-names></name><name><surname>Hayat</surname><given-names>MM</given-names></name></person-group><article-title>Kalman filtering for adaptive nonuniformity correction in infrared focal-plane arrays</article-title><source>Journal of the Optical Society of America. A, Optics, image science, and vision</source><year>2003</year><volume>20</volume><fpage>470</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.20.000470</pub-id><?supplied-pmid 12630832?><pub-id pub-id-type="pmid">12630832</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayat</surname><given-names>MM</given-names></name><name><surname>Torres</surname><given-names>SN</given-names></name><name><surname>Armstrong</surname><given-names>E</given-names></name><name><surname>Cain</surname><given-names>SC</given-names></name><name><surname>Yasuda</surname><given-names>B</given-names></name></person-group><article-title>Statistical algorithm for nonuniformity correction in focal-plane arrays</article-title><source>Applied optics</source><year>1999</year><volume>38</volume><fpage>772</fpage><lpage>780</lpage><pub-id pub-id-type="doi">10.1364/AO.38.000772</pub-id><?supplied-pmid 18305675?><pub-id pub-id-type="pmid">18305675</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardie</surname><given-names>RC</given-names></name><name><surname>Hayat</surname><given-names>MM</given-names></name><name><surname>Armstrong</surname><given-names>E</given-names></name><name><surname>Yasuda</surname><given-names>B</given-names></name></person-group><article-title>Scene-based nonuniformity correction with video sequences and registration</article-title><source>Applied Optics</source><year>2000</year><volume>39</volume><fpage>1241</fpage><lpage>1250</lpage><pub-id pub-id-type="doi">10.1364/AO.39.001241</pub-id><?supplied-pmid 18338007?><pub-id pub-id-type="pmid">18338007</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezoa</surname><given-names>JE</given-names></name><name><surname>Hayat</surname><given-names>MM</given-names></name><name><surname>Torres</surname><given-names>SN</given-names></name><name><surname>Rahman</surname><given-names>MS</given-names></name></person-group><article-title>Multimodel Kalman filtering for adaptive nonuniformity correction in infrared sensors</article-title><source>Journal of the Optical Society of America. A, Optics, image science, and vision</source><year>2006</year><volume>23</volume><fpage>1282</fpage><lpage>1291</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.23.001282</pub-id><?supplied-pmid 16715146?><pub-id pub-id-type="pmid">16715146</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Godoy</surname><given-names>SE</given-names></name><name><surname>Pezoa</surname><given-names>JE</given-names></name><name><surname>Torres</surname><given-names>SN</given-names></name></person-group><article-title>Noise-cancellation-based nonuniformity correction algorithm for infrared focal-plane arrays</article-title><source>Applied Optics</source><year>2008</year><volume>47</volume><fpage>5394</fpage><lpage>5399</lpage><pub-id pub-id-type="doi">10.1364/AO.47.005394</pub-id><?supplied-pmid 18846181?><pub-id pub-id-type="pmid">18846181</pub-id></element-citation></ref></ref-list></back></article>